ğŸŒ README.md â€” Sistema de DetecciÃ³n de Fraude con Databricks Lakehouse

Autora: Sonia Guevara
Materia: Analisis de Datos en la Nube â€” UNCUYO
Proyecto Profesional â€” Lakehouse + ML Distribuido

ğŸ“š Ãndice

ğŸ¦ DescripciÃ³n General

ğŸ—ï¸ Arquitectura del Proyecto

ğŸ§ª Dataset Utilizado

ğŸš€ Etapas del Proyecto

ğŸ”¶ Etapa 0 â€” PreparaciÃ³n del Entorno

ğŸ”¶ Etapa 1 â€” Capa Silver

ğŸ”¶ Etapa 2 â€” Machine Learning Distribuido

ğŸ”¶ Etapa 3 â€” Visualizaciones

ğŸ”¶ Etapa 4 â€” Capa Gold

ğŸ“Š MÃ©tricas del Modelo

ğŸ—‚ï¸ Estructura del Repositorio

ğŸ’¾ InstalaciÃ³n Local

ğŸ“Œ Conclusiones

ğŸ‘©â€ğŸ’» Autora

ğŸ¦ DescripciÃ³n General

Este proyecto implementa un sistema completo de detecciÃ³n de fraude utilizando:

Apache Spark

Delta Lake

Databricks Lakehouse

Algoritmos de Machine Learning distribuidos

Visualizaciones y anÃ¡lisis avanzados

El objetivo es construir una arquitectura profesional de datos capaz de procesar cientos de miles de transacciones y detectar actividad fraudulenta.

ğŸ—ï¸ Arquitectura del Proyecto

<details> <summary>ğŸ“Œ Mostrar Esquema</summary>
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Dataset Kaggle CSV             â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       (Ingesta Batch)
                                â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                BRONZE                   â”‚
           â”‚ Datos crudos sin transformar            â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                     (Limpieza + Enriquecimiento)
                                â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                SILVER                   â”‚
           â”‚ Datos limpios + metadata de usuarios    â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       (PredicciÃ³n ML)
                                â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                 GOLD                    â”‚
           â”‚ Datos listos para BI / dashboards       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

</details>
ğŸ§ª Dataset Utilizado

Credit Card Fraud Detection (Kaggle)
âœ” 284.807 transacciones
âœ” 492 fraudes
âœ” 30 features numÃ©ricos transformados con PCA
âœ” Desbalanceado â†’ ideal para ML realista

AdemÃ¡s, se generÃ³ una tabla adicional de usuarios:

edad

nivel de riesgo

monto promedio

user_id

comportamiento simulado realista

ğŸš€ Etapas del Proyecto
ğŸ”¶ Etapa 0 â€” PreparaciÃ³n del Entorno

ğŸ“Œ Se realizÃ³:

ConfiguraciÃ³n de base de datos: lakehouse_fraude

Descarga del dataset vÃ­a kagglehub

ConversiÃ³n CSV â†’ Pandas â†’ Spark

Tabla Bronze persistida en Delta

Tabla ref_usuarios generada con reglas realistas

Reglas para clasificar riesgo:

Nivel Criterio
ALTO monto_promedio > 6000 y edad < 25
MEDIO monto_promedio entre 3000 y 6000
BAJO resto
ğŸ”¶ Etapa 1 â€” Capa Silver

IncluyÃ³:

Limpieza (tipos numÃ©ricos, nulos, duplicados)

Enriquecimiento con metadata de usuarios

Persistencia en tabla Silver

Validaciones de esquema, conteo y muestras

ğŸ”¶ Etapa 2 â€” Machine Learning Distribuido

Se entrenÃ³ un modelo con Spark MLlib usando:

âœ” VectorAssembler
âœ” Logistic Regression
âœ” Split 80/20
âœ” Predicciones y probabilidades

El modelo se entrenÃ³ con mÃ¡s de 280k filas procesadas de forma distribuida.

ğŸ”¶ Etapa 3 â€” Visualizaciones

GrÃ¡ficos generados automÃ¡ticamente:

ğŸ“ˆ Curva ROC

ğŸ“‰ Curva Precisionâ€“Recall

ğŸ”¢ Matriz de confusiÃ³n

ğŸŸ¦ Histograma de probabilidades

ğŸŸ§ DistribuciÃ³n por niveles de riesgo

ğŸ”¶ Etapa 4 â€” Capa Gold

La tabla GOLD incluye:

PredicciÃ³n final

Probabilidad de fraude

Datos de usuario

Monto total

Features completos

Nivel de riesgo

Estructura lista para dashboards

âœ” Compatible con Databricks SQL, Power BI, Looker Studio.

ğŸ“Š MÃ©tricas del Modelo
MÃ©trica Valor
AUC ROC â­ 0.95
AUC PR 0.66
Precision (fraude) 0.84
Recall (fraude) 0.59
F1-score 0.69

InterpretaciÃ³n:

El modelo distingue bien transacciones legÃ­timas vs fraudulentas

Muy pocas falsas alarmas

Se escapan algunos fraudes (recall tÃ­pico en datasets desbalanceados)

ğŸ—‚ï¸ Estructura del Repositorio
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ CreditCard_Lakehouse.ipynb
â”‚ â””â”€â”€ CreditCard_Lakehouse.html
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ creditcard.csv
â”‚ â””â”€â”€ README_data.md
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ metrics/
â”‚ â”œâ”€â”€ charts/
â”œâ”€â”€ diagrams/
â”‚ â””â”€â”€ lakehouse_architecture.png
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸ’¾ InstalaciÃ³n Local
pip install -r requirements.txt
jupyter notebook notebooks/CreditCard_Lakehouse.ipynb

ğŸ“Œ Conclusiones

Este proyecto demuestra:

Dominio de Big Data

Arquitecturas modernas Lakehouse

Procesamiento distribuido

Modelos de Machine Learning escalables

Visualizaciones profesionales

Pipeline completo desde datos crudos hasta insights

Es un trabajo totalmente apto para:

âœ¨ Portfolio
âœ¨ Entrevistas tÃ©cnicas
âœ¨ Presentaciones acadÃ©micas
